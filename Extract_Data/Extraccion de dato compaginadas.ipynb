{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Extraccion de dato compaginadas.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yn2taiklT6fm","executionInfo":{"elapsed":4036,"status":"ok","timestamp":1608179787421,"user":{"displayName":"Rodrigo Gil","photoUrl":"","userId":"04585480583099678050"},"user_tz":-60},"outputId":"73bbe463-37ad-4fa5-ab93-505f8c24f828"},"source":["import sys\n","from selenium import webdriver\n","from selenium.webdriver.common.keys import Keys\n","import time\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import re"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def aceptar_cookies(año, liga, jornada = None):\n","    '''\n","    Inicia el driver de un año, liga y jornada que accede\n","    al código de la página para extraer los datos\n","\n","    Parameters\n","    ----------\n","    año: int\n","        Año de los datos a extraer\n","    liga: str\n","        Nombre de la liga de los datos a extraer\n","    jornada: int\n","        Número de la jornada a partir de la cual empezar la búsqueda\n","        En caso de no especificarlo, el driver a la página principal\n","        la cual corresponde a la última jornada de ese año\n","    \n","    Returns\n","    -------\n","    driver: webdriver\n","        Elemento webdriver con los datos de la página con los datos del \n","        año, liga y jornada. Se usará este driver para extraer el código html\n","    '''\n","    \n","    driver_dir = 'chrome_driver/chromedriver.exe'\n","    driver=webdriver.Chrome(driver_dir)\n","    if jornada:\n","        driver.get(\"https://www.resultados-futbol.com/\"+liga+str(año)+\"/grupo1/jornada\"+str(jornada))\n","    else:\n","        driver.get(\"https://www.resultados-futbol.com/\"+liga+str(año))\n","\n","    accept_cookies = driver.find_elements_by_xpath('//button[@class=\"sc-ifAKCX hYNOwJ\"]')\n","    \n","    try:\n","        for button in accept_cookies:\n","            if button.text == \"ACEPTO\":\n","                relevant_button = button\n","                relevant_button.click()\n","    except:\n","        pass\n","    finally:\n","        return driver"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[]},"outputs":[],"source":["def extraer_datos_jornada(soup):\n","    '''\n","    Devuelve los datos de la tabla de posiciones\n","\n","    Parameters\n","    ----------\n","    soup: BeautifulSoup\n","        Contiene toda la información del código html de la \n","        página con los datos sobre el año, liga y jornada\n","\n","    Returns\n","    -------\n","    tabla_jornada: list\n","        Si el scraping ha salido bien, devuelve una lista de listas con:\n","        Posicion, Equipo, Puntos, Jornada, Partidos ganados, Partidos empatados,\n","        Partidos perdidos, Goles a favor, y goles en contra\n","        En caso de que haya habido algún problema, tabla_jornada se convierte en \n","        una lista de valores nulos\n","    '''\n","    \n","    if soup.find(\"table\", {\"id\": 'tabla2'}):\n","        table_soup = soup.find(\"table\", {\"id\": 'tabla2'}).find('tbody').find_all('tr')\n","    else:\n","        return None\n","    num_equipos = len(table_soup)\n","\n","    Posicion = [table_soup[i].find('th').text for i in range(num_equipos)]\n","    Equipo = [table_soup[i].find('td', {'class':'equipo'}).find('a').text for i in range(num_equipos)]\n","    Puntos = [table_soup[i].find('td', {'class':'pts'}).text for i in range(num_equipos)]\n","    Jornada = [table_soup[i].find('td', {'class':'pj'}).text for i in range(num_equipos)]\n","    Ganados = [table_soup[i].find('td', {'class':'win'}).text for i in range(num_equipos)]\n","    Empatados = [table_soup[i].find('td', {'class':'draw'}).text for i in range(num_equipos)]\n","    Perdidos = [table_soup[i].find('td', {'class':'lose'}).text for i in range(num_equipos)]\n","    Goles_a_favor= [table_soup[i].find('td', {'class':'f'}).text for i in range(num_equipos)]\n","    Goles_en_contra= [table_soup[i].find('td', {'class':'c'}).text for i in range(num_equipos)]\n","\n","    tabla_jornada = [Posicion, Equipo, Puntos, Jornada, Ganados, Empatados, Perdidos, Goles_a_favor, Goles_en_contra]\n","\n","    # Nos aseguramos que ningun dato se ha saltado, y que hemos encontrado todos\n","    if len(set([len(i) for i in tabla_jornada])) == 1:\n","        return tabla_jornada\n","    else:\n","        return [None] * len(tabla_jornada)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def extraer_datos_partido(soup):\n","    '''\n","    Devuelve los datos de la tabla de partidos\n","\n","    Parameters\n","    ----------\n","    soup: BeautifulSoup\n","        Contiene toda la información del código html de la \n","        página con los datos sobre el año, liga y jornada\n","\n","    Returns\n","    -------\n","    tabla_partido: list\n","        Si el scraping ha salido bien, devuelve una lista de listas con:\n","        Nombre del equipo local, nombre del equipo visitante, resultado del partido\n","        y fecha del partido\n","        En caso de que haya habido algún problema, tabla_partido se convierte en \n","        una lista de valores nulos\n","    '''\n","\n","    regex = re.compile('vevent')\n","    if soup.find(\"table\", {\"id\": 'tabla1'}):\n","        table_soup = soup.find(\"table\", {\"id\": 'tabla1'}).find('tbody').find_all(\"tr\", {\"class\" : regex})\n","    else:\n","        return None\n","    \n","    num_partidos = len(table_soup)\n","    Equipo_Local = [table_soup[i].find('td', {'class':'equipo1'}).find_all('a')[1].text for i in range(num_partidos)]\n","    Equipo_Visitante = [table_soup[i].find('td', {'class':'equipo2'}).find_all('a')[1].text for i in range(num_partidos)]\n","    Resultado = [table_soup[i].find('td', {'class':'rstd'}).find('a', {'class':'url'}).find('span').text for i in range(num_partidos)]\n","    Fecha = [table_soup[i].find('td', {'class':'fecha'}).text for i in range(num_partidos)]\n","\n","    tabla_partido = [Equipo_Local, Equipo_Visitante, Resultado, Fecha]\n","\n","    # Nos aseguramos que ningun dato se ha saltado, y que hemos encontrado todos\n","    if len(set([len(i) for i in tabla_partido])) == 1:\n","        return tabla_partido\n","    else:\n","        return [None] * len(tabla_partido)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def extraer_num_jornadas(soup):\n","    '''\n","    Devuelve el número de jornadas correspondiente a un año y liga en concreto\n","\n","    Parameters\n","    ----------\n","    soup: BeautifulSoup\n","        Contiene toda la información del código html de la \n","        página con los datos sobre el año, liga y jornada\n","\n","    Returns\n","    -------\n","    int\n","        Si la página tiene información acerca de las jornadas correspondiente a ese año\n","        y liga, devuelve el número de jornadas\n","        En caso contrario, devuelve 0\n","    '''\n","\n","    if soup.find(\"div\", {\"id\":'desplega_jornadas', \"class\":'hidden'}) :\n","        jornadas_soup = soup.find(\"div\", {\"id\":'desplega_jornadas', \"class\":'hidden'}).find_all('li')\n","        return len(jornadas_soup)\n","    else:\n","        return 0"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def extraccion_datos(año1, año2, *Ligas, primera_jornada = 1):\n","    '''\n","    Busca datos sobre posiciones y partidos entre los años entre \n","    año1 y año2, para las ligas incluidas en *Ligas\n","    Actualiza una variable global correspondiente a un diccionario.\n","    Dicho diccionario obtiene sus keys de una lista con las keys deseadas.\n","    Una vez actualizado el diccionario, crea un dataframe y lo exporta a\n","    un archivo excel.\n","\n","    Parameters\n","    ----------\n","    año1: int\n","        Año a partir del cual empezar la búsqueda\n","    año2: int\n","        Año a partir del cual finalizar la búsqueda\n","    *Ligas: str\n","        Nombre de las ligas para realizar la búsqueda\n","    primera_jornada: int, default = 1\n","        Número de la jornada a partir de la cual empezar la búsqueda\n","\n","    Returns\n","    -------\n","    list\n","        Lista que contiene el nombre de las ligas de las cuales se ha\n","        realizado la búsqueda\n","    DDBB_Resultado : xlsx\n","        Exporta a un archivo excel los datos sobre los partidos jugados entre el\n","        año1 y año2 en las ligas *Liga\n","    DDBB_Tabla : xlsx\n","        Exporta a un archivo excel los datos sobre los posiciones de los equipos #\n","        entre el año1 y año2 en las ligas *Liga\n","    '''\n","    for liga in Ligas:\n","        for año in range(año1, año2 + 1):\n","            print(f'Extrayendo datos del año {año} de la liga {liga}') \n","            driver = aceptar_cookies(año, liga) # Accedemos simplemente a la primera jornada de ese año para comprobar cuantas jornadas hubo ese año\n","            page = driver.page_source\n","            soup = BeautifulSoup(page, 'html.parser')\n","            num_jornadas = extraer_num_jornadas(soup)\n","            if num_jornadas == 0:\n","                print(f'No hay datos disponibles para el año {año} en la liga {liga}')\n","                print('Saltando al siguiente año')\n","                driver.quit()\n","                continue\n","            driver.quit()\n","            for jornada in range(primera_jornada, num_jornadas + 1):\n","                print(f'\\tExtrayendo jornada numero {jornada} del año {año}') \n","                driver = aceptar_cookies(año, liga, jornada)\n","                page = driver.page_source\n","                soup = BeautifulSoup(page, 'html.parser')\n","                tabla_jornada = extraer_datos_jornada(soup)\n","                tabla_partido = extraer_datos_partido(soup)\n","\n","                if tabla_jornada == None or tabla_partido == None: # Esto significaría que, a pesar de que la página diga que esa jornada tiene datos, en realidad durante ese año no hubo más jornadas. De esa manera, sale del 'for' de las jornadas, y pasa al siguiente año\n","                    print(f'------------------------------------------------------')\n","                    print(f'!!! La jornada {jornada} no existe en el año {año} !!!')\n","                    print(f'!!!            Saltando al siguiente año           !!!')\n","                    print(f'------------------------------------------------------')\n","                    driver.quit()\n","                    break\n","                \n","                for i, key in enumerate(list_jornadas[:-2]):\n","                    dict_jornadas[key].extend(tabla_jornada[i])\n","\n","                dict_jornadas['Año'].extend([año] * len(tabla_jornada[0]))\n","                dict_jornadas['Liga'].extend([liga] * len(tabla_jornada[0]))\n","\n","                for i, key in enumerate(list_partidos[:-3]):\n","                    dict_partidos[key].extend(tabla_partido[i])\n","\n","                dict_partidos['Año_partido'].extend([año] * len(tabla_partido[0]))\n","                dict_partidos['Jornada_partido'].extend([jornada] * len(tabla_partido[0]))\n","                dict_partidos['Liga_partido'].extend([liga] * len(tabla_partido[0]))\n","               \n","                print(f'\\tDatos extraídos, quedan {num_jornadas - jornada} jornadas restantes este año')\n","                driver.quit()\n","            print(f'Datos del año {año} extraídos, queda(n) {año2 - año} año(s) restante(s)')\n","            primera_jornada = 1\n","        \n","        Data_Tabla = pd.DataFrame(dict_jornadas).drop_duplicates()\n","        Data_Tabla.to_excel(f\"DDBB_Tabla_{año_1}_{año_2}_{liga}.xlsx\")\n","        for key in list_jornadas:\n","            dict_jornadas[key].clear()\n","\n","        Data_Partido = pd.DataFrame(dict_partidos).drop_duplicates()\n","        Data_Partido.columns = ['Equipo_Local', 'Equipo_Visitante', 'Resultado', 'Fecha', 'Año', 'Jornada', 'Liga']\n","        Data_Partido.to_excel(f\"DDBB_Resultados_{año_1}_{año_2}_{liga}.xlsx\")\n","        for key in list_partidos:\n","            dict_partidos[key].clear()\n","    return list(Ligas)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["list_jornadas = ['Posicion', 'Equipo', 'Puntos', 'Jornada', 'Ganados', 'Empatados', 'Perdidos', 'Goles_a_favor', 'Goles_en_contra', 'Año', 'Liga'] \n","list_partidos = ['Equipo_Local', 'Equipo_Visitante', 'Resultado', 'Fecha', 'Año_partido', 'Jornada_partido', 'Liga_partido']\n","dict_jornadas = {x:[] for x in list_jornadas}\n","dict_partidos = {x:[] for x in list_partidos}"]},{"cell_type":"code","execution_count":18,"metadata":{"tags":[]},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-18-15514ee6afb8>, line 3)","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-15514ee6afb8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    Ligas = extraccion_datos(año_1, año_2, 'primera', 'segunda', 'premier', 'championship', 'ligue_1'. 'ligue_2', 'serie_a', 'serie_b')\u001b[0m\n\u001b[1;37m                                                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["año_1 = 1990\n","año_2 = 2020\n","Ligas = extraccion_datos(año_1, año_2, 'primera', 'segunda', 'premier', 'championship', 'ligue_1', 'ligue_2', 'serie_a', 'serie_b')"]}]}